{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ../fib.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fib import fibonacci\n",
    "fibonacci(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fib 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fib -l 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subprocess - a poor man's multiprocessing\n",
    "\n",
    "The [subprocess](https://docs.python.org/3/library/subprocess.html#module-subprocess) module allows you to spawn new processes, connect to their input/output/error pipes, and obtain their return codes. Subprocess is a built in module,  you should not need to install it.  Simply ```import subprocess```\n",
    "\n",
    "**subprocess allows you to run shell commands from python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subprocess.check_output(...) allows you to run a command. It returns the output as bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.check_output([\"ls\", \"/\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A few things to note:\n",
    "\n",
    "+ In Python 3 b'...' means the return value is bytes. Python 2 assumed that the return value is a string. This leads to all kinds of problems if what you're working with are actually bytes.\n",
    "+ The output contains a few special characters, specifically '\\n'. '\\n'  means \"carriage return\" and you can treat it like a normal character in Python.\n",
    "\n",
    "Python makes it is easy to convrt bytes into a string (assuming the bytes are a string!). To do so we can add .decode(...) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.check_output([\"ls\", \"/\"]).decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can split up the output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.check_output([\"ls\", \"/\"]).decode('utf-8').split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With ```subprocess.check_output(...)``` we can call our ```fib``` executable directly from Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.check_output([\"fib\", \"20\"]).decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.check_output([\"fib\", \"-l\", \"20\"]).decode('utf-8').split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "subprocess.check_output(...) returns the output.   subprocess.check_call(...) returns the \"return code.\"  This an operating system level 'code'  where 0 is (almost) always good,  and any other number means failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.check_call([\"fib\", \"20\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.check_call([\"fib\", \"not\", \"a\", \"command\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```subprocess.check_output(...)``` and ```subprocess.check_call(...)```\n",
    "are both functions that wrap a lower level function called Popen().  Until now each of the functions in subprocess have pitched their computation to the operating system and waited.  Popen (the 'low-level' API) run's it's process in the background.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = subprocess.Popen([\"fib\", \"-l\", \"34\"], stdout=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process is now running,  but the notebook can execute additional cells,  you are free to go on doing additional work.  You can tell when the process is finished by calling ```p.poll()``` if it returns None it is not finished,  if it returns 0 (the return code)  then it is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.poll() is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can get access to the output of the ```stdout``` attribute of the process. But careful!  you can only get that data once! Make sure to put it in a variable if you want to hang onto it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.stdout.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.stdout.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Popen() it is possible to run as many commands as you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p1 = subprocess.Popen([\"fib\", \"-l\", \"34\"], stdout=subprocess.PIPE)\n",
    "p2 = subprocess.Popen([\"fib\", \"-l\", \"34\"], stdout=subprocess.PIPE)\n",
    "p3 = subprocess.Popen([\"fib\", \"-l\", \"34\"], stdout=subprocess.PIPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1.poll() == 0 and p2.poll() == 0 and p3.poll() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for fun,  it is possible to dynamically read the output of a command and print the value.  Unfortunately,  reading like this forces the cell to 'block.'  It is possible to not block, still get output and handle a several processes but that is outside the scope of this presentation.  If you're interested take a look at the built-in module [select](https://docs.python.org/3/library/select.html)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p = subprocess.Popen([\"fib\", \"-l\", \"34\"], stdout=subprocess.PIPE)\n",
    "for line in iter(p.stdout.readline, b''):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiprocessing\n",
    "\n",
    "Multiprocessing gives us many more options over ```subprocess.```  Multiprocessing works with functions,  rather than command line commands - this means we can write a function, pass it arguments, and smear it over a bunch of processors to get things done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "from fib import fibonacci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pools are a much more convenient way to distribute a function across a number of arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = mp.Pool(3)\n",
    "\n",
    "result = pool.apply_async(fibonacci, (34, ))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool = mp.Pool(3)\n",
    "jobs = []\n",
    "\n",
    "for value in [34, 35, 36]:\n",
    "    result = pool.apply_async(fibonacci, (value, ))\n",
    "    jobs.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[j.get() for j in jobs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multiprocessing ```map(...)``` function is quite useful. Note that the map function blocks until all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool = mp.Pool(3)\n",
    "values = pool.map(fibonacci, [34, 34, 34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiprocessing provides many mechanisms for sychronising between processes including Queues, Pipes, Locks, Semaphores, Events and shared memory between processes via Values and Arrays. There are interestesting things that allow you to coordinate between processes, but they are also drastically increse the complexity of any program that uses them. Because of this I won't cover them in this presentation. For more information checkout the [multiprocessing](https://docs.python.org/3.6/library/multiprocessing.html) documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a quick example of using multiprocessing to run a subprocess that returns outputs.  Recall before that ```subprocess.check_output(...)``` 'blocks' until it returns a value (the output of the shell command). By wrapping the subprocess call in a call to ```multiprocessing.map(...)``` we launch each function in its own process, which calls ```subprocess.check_output(...)``` waiting for the output to return.  The entire cell blocks until each of the ```multiprocessing.map(...)``` functions returns. This should only take as long as the _longest_ running function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import subprocess\n",
    "\n",
    "def run_fib(N):\n",
    "    return subprocess.check_output([\"fib\", str(N)]).decode('utf-8')\n",
    "\n",
    "pool = mp.Pool(3)\n",
    "\n",
    "pool.map(run_fib, [32, 33, 34])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPython Parallel\n",
    "\n",
    "To get IPython Parallel up and running we have to start a cluster. The easiest way to do this is by running the following command:\n",
    "\n",
    "```\n",
    "ipcluster start -n 4\n",
    "```\n",
    "\n",
    "The '4' above indicates that we want to have 4 \"engines\"  or \"workers\" This allows us to run the cluster locally, using as many processors as we have available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ipyparallel as ipp\n",
    "from fib import fibonacci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a \"Client\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = ipp.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Direct View "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dview = c[:]\n",
    "dview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel Map\n",
    "\n",
    "```map_sync()``` works like multiprocessing's map(...) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "serial = list(map(fibonacci, range(25)))\n",
    "serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parallel = dview.map_sync(fibonacci, range(25))\n",
    "parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serial == parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing map_sync\n",
    "Timing a run of 4 fibonacci numbers,  serial vs. parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r1\n",
    "list(map(fibonacci, [N, N, N, N]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n1 -r1\n",
    "dview.map_sync(fibonacci, [N, N, N, N])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remote function decorators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@dview.remote(block=True)\n",
    "def remote_fib(N):\n",
    "    from fib import fibonacci\n",
    "    return fibonacci(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not what you might expect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "remote_fib(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Didn't run ```remote_fib(32)``` on a single worker,  it ran the **same** function on each worker!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push/Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dview['some_var'] = 32\n",
    "# Same as: dview.push(dict(some_var=32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dview['some_var']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dview.remote(block=True)\n",
    "def return_some_var():\n",
    "    global some_var\n",
    "    return some_var\n",
    "    \n",
    "return_some_var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dview.remote(block=True)\n",
    "def change_some_var():\n",
    "    global some_var\n",
    "    import random\n",
    "    some_var = some_var + random.randint(1, 5)\n",
    "    \n",
    "change_some_var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dview['some_var']\n",
    "# Same as: dview.pull(\"some_var\").get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syncing imports\n",
    "\n",
    "importing nessisary libraries can be quite annoying if you're defining many functions.  It is possible to sync imports using a context manager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with dview.sync_imports():\n",
    "    from fib import fibonacci\n",
    "    import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@dview.remote(block=True)\n",
    "def remote_fib_better():\n",
    "    global seed_var\n",
    "    N = seed_var + random.randint(1, 4)\n",
    "\n",
    "    return (N, fibonacci(N))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dview['seed_var'] = 25\n",
    "\n",
    "remote_fib_better()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scatter & Gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numbers = list(range(32))\n",
    "random.shuffle(numbers)\n",
    "numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dview.scatter('Ns', numbers)\n",
    "dview['Ns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dview.remote(block=True)\n",
    "def scattered_fib():\n",
    "    global Ns\n",
    "    Ns = [fibonacci(n) for n in Ns]\n",
    "    \n",
    "scattered_fib()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dview.gather('Ns').get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magic Commands\n",
    "\n",
    "You must instantiate a ```Client()``` before these commands will work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%px print(\"Hello there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with dview.sync_imports():\n",
    "    import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%px print(\"Hello from {}\".format(os.getpid()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dview.scatter('Ns', numbers)\n",
    "dview['Ns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "from fib import fibonacci\n",
    "outputs = []\n",
    "for i in Ns:\n",
    "    outputs.append(fibonacci(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dview.gather('outputs', block=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running IPython Parallel across multiple computers\n",
    "\n",
    "Running a ipyparallel cluster across multiple computers is a little more complicated.  First, on the same machine you are running the notebook,  you must run:\n",
    "\n",
    "```\n",
    "ipcontroller --ip='<machine-ip-here>'\n",
    "```\n",
    "\n",
    "This will create a file in ```~/.ipython/profile_default/security/ipcontroller-engine.json```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat ~/.ipython/profile_default/security/ipcontroller-engine.json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This needs to be copied into a file on each remote machine at the same location (``` ~/.ipython/profile_default/security/ipcontroller-engine.json```). Then,  on the machine you must run:\n",
    "\n",
    "```\n",
    "ipengine\n",
    "```\n",
    "\n",
    "This should give a little output that looks like the following:\n",
    "\n",
    "```\n",
    "2017-05-10 22:29:27.953 [IPEngineApp] Loading url_file '/home/ubuntu/.ipython/profile_default/se\n",
    "curity/ipcontroller-engine.json'\n",
    "2017-05-10 22:29:27.960 [IPEngineApp] Registering with controller at tcp://172.30.0.39:48491\n",
    "2017-05-10 22:29:28.015 [IPEngineApp] Starting to monitor the heartbeat signal from the hub ever\n",
    "y 3010 ms.\n",
    "2017-05-10 22:29:28.019 [IPEngineApp] Completed registration with id 2\n",
    "```\n",
    "\n",
    "The importaint part is \"Completed registration with id ...\".  Once complete You should be able to load a client,  and distribute functions to the remote machines just as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = ipp.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dv = client[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv.scatter('Ns', numbers)\n",
    "dv['Ns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%px\n",
    "from fib import fibonacci\n",
    "outputs = []\n",
    "for i in Ns:\n",
    "    outputs.append(fibonacci(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv.gather('outputs', block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dask thing huh?\n",
    "# executor = client.become_dask(ncores=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Celery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from celery_example.tasks import fibonacci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = fibonacci.delay(30)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "tasks = [fibonacci.delay(30 + random.randint(1, 5)) for _ in range(10)]\n",
    "tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[t.revoke() for t in tasks]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
